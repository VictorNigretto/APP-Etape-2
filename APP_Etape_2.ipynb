{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APP Etape 2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPrvutFyzGQy"
      },
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "import keras\r\n",
        "from keras import layers, models, optimizers\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers import Dense, Flatten, Dropout, Input\r\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.models import Model\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY-eAP0O0O12",
        "outputId": "599b056f-04b1-4989-c58f-34aee7bae09f"
      },
      "source": [
        "# Dataset personnes\r\n",
        "!git clone https://gitlab.enseeiht.fr/aandre2/Dataset_Market-1501-v15.09.15\r\n",
        "\r\n",
        "# Dataset pokemons\r\n",
        "!git clone https://gitlab.enseeiht.fr/nurbani/dataset-pokemon\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dataset_Market-1501-v15.09.15'...\n",
            "warning: redirecting to https://gitlab.enseeiht.fr/aandre2/Dataset_Market-1501-v15.09.15.git/\n",
            "remote: Counting objects: 77323, done.\u001b[K\n",
            "remote: Compressing objects: 100% (70371/70371), done.\u001b[K\n",
            "^C\n",
            "Cloning into 'dataset-pokemon'...\n",
            "warning: redirecting to https://gitlab.enseeiht.fr/nurbani/dataset-pokemon.git/\n",
            "remote: Counting objects: 26364, done.\u001b[K\n",
            "remote: Compressing objects: 100% (25090/25090), done.\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8uOiUHSFPSK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBVyD65iAUj6"
      },
      "source": [
        "On commence par les chemins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEW4cZba4KH9"
      },
      "source": [
        "path_pokemon = \"/content/dataset-pokemon/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgzVLXTw4mRK"
      },
      "source": [
        "#Chemin vers les pokemon qu'on va utiliser\r\n",
        "pokemon_1G_red_blue = os.listdir(path_pokemon + '1G-red-blue')[:151]\r\n",
        "pokemon_1G_red_green = os.listdir(path_pokemon + '1G-red-green')[:151]\r\n",
        "pokemon_1G_yellow = os.listdir(path_pokemon + '1G-yellow')[:151]\r\n",
        "pokemon_2G_crystal = os.listdir(path_pokemon + '2G-crystal')[:151]\r\n",
        "pokemon_2G_gold = os.listdir(path_pokemon + '2G-gold')[:151]\r\n",
        "pokemon_2G_silver = os.listdir(path_pokemon + '2G-silver')[:151]\r\n",
        "pokemon_3G_emerald = os.listdir(path_pokemon + '3G-emerald')[:151]\r\n",
        "pokemon_3G_firered_leafgreen = os.listdir(path_pokemon + '3G-firered-leafgreen')[:151]\r\n",
        "pokemon_3G_ruby_sapphire = os.listdir(path_pokemon + '3G-ruby-sapphire')[:151]\r\n",
        "pokemon_4G_diamond_pearl = os.listdir(path_pokemon + '4G-diamond-pearl')[:151]\r\n",
        "pokemon_4G_heartgold_soulsilver = os.listdir(path_pokemon + '4G-heartgold-soulsilver')[:151]\r\n",
        "pokemon_4G_platinum = os.listdir(path_pokemon + '4G-platinum')[:151]\r\n",
        "pokemon_5G_black_white = os.listdir(path_pokemon + '5G-black-white')[:151]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNn9e-AXAXNr"
      },
      "source": [
        "Création du fichier de données d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPVrSSaQksSC"
      },
      "source": [
        "# path train\r\n",
        "path_train_pokemon = path_pokemon + \"train/\"\r\n",
        "\r\n",
        "# train folder\r\n",
        "if not os.path.exists(path_train_pokemon):\r\n",
        "  os.mkdir(path_train_pokemon)\r\n",
        "\r\n",
        "# train images\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"1G-red-blue/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-1G-red-blue.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"1G-red-green/\" + str(filename) +'.png', path_train_pokemon + str(filename) + '-1G-red-green.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"1G-yellow/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-1G-yellow.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"2G-crystal/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-2G-crystal.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"2G-gold/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-2G-gold.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"2G-silver/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-2G-silver.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"3G-emerald/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-3G-emerald.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"3G-firered-leafgreen/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-3G-firered-leafgreen.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"3G-ruby-sapphire/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-3G-ruby-sapphire.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"4G-diamond-pearl/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-4G-diamond-perl.png')\r\n",
        "\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"4G-heartgold-soulsilver/\" + str(filename) + '.png', path_train_pokemon + str(filename) + '-4G-heartgold-soulsilver.png')\r\n",
        "\r\n",
        "# train labels\r\n",
        "train_filenames = os.listdir(path_train_pokemon)\r\n",
        "train_categories=[]\r\n",
        "for filename in train_filenames:\r\n",
        "    train_categories.append(filename.split('-')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrbTzeKfAZbG"
      },
      "source": [
        "Création du fichier des données de validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3nRHz36TWW"
      },
      "source": [
        "# path validation\r\n",
        "path_validation_pokemon = path_pokemon + \"validation/\"\r\n",
        "\r\n",
        "# validation folder\r\n",
        "if not os.path.exists(path_validation_pokemon):\r\n",
        "  os.mkdir(path_validation_pokemon)\r\n",
        "\r\n",
        "\r\n",
        "# Creation\r\n",
        "if not os.path.exists(path_validation_pokemon):\r\n",
        "  os.mkdir(path_validation_pokemon)\r\n",
        "\r\n",
        "# Validation images\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"5G-black-white/\" + str(filename) + '.png', path_validation_pokemon + str(filename) + '-5G-black-white.png')\r\n",
        "\r\n",
        "# validation labels\r\n",
        "validation_filenames = os.listdir(path_validation_pokemon)\r\n",
        "validation_categories=[]\r\n",
        "for filename in validation_filenames:\r\n",
        "  validation_categories.append(filename.split('-')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4j0i6CQAbgl"
      },
      "source": [
        "Création du fichier des données de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4vSz1Lm8bN2"
      },
      "source": [
        "# path test\r\n",
        "path_test_pokemon = path_pokemon + \"test/\"\r\n",
        "\r\n",
        "# testfolder\r\n",
        "if not os.path.exists(path_test_pokemon):\r\n",
        "  os.mkdir(path_test_pokemon)\r\n",
        "\r\n",
        "\r\n",
        "# Test images\r\n",
        "for filename in range(1, 152):\r\n",
        "  shutil.copyfile(path_pokemon + \"4G-platinum/\" + str(filename) + '.png', path_test_pokemon + str(filename) + '-4G-platinum.png')\r\n",
        "\r\n",
        "# Test labels\r\n",
        "test_filenames = os.listdir(path_test_pokemon)\r\n",
        "test_categories=[]\r\n",
        "for filename in test_filenames:\r\n",
        "  test_categories.append(filename.split('-')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFkZCZj38f7"
      },
      "source": [
        "Création des ensemble d'apprentissage, test et validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqkrGGRd91vf"
      },
      "source": [
        "#Images d'entrainement\r\n",
        "train_df = pd.DataFrame({\r\n",
        "    'filename': train_filenames,\r\n",
        "    'category': train_categories\r\n",
        "})\r\n",
        "\r\n",
        "\r\n",
        "#Images de validation\r\n",
        "validation_df = pd.DataFrame({\r\n",
        "    'filename': validation_filenames,\r\n",
        "    'category': validation_categories\r\n",
        "})\r\n",
        "\r\n",
        "\r\n",
        "#Images de test\r\n",
        "test_df = pd.DataFrame({\r\n",
        "    'filename': test_filenames,\r\n",
        "    'category': test_categories\r\n",
        "})\r\n",
        "\r\n",
        "\r\n",
        "train_df['category'] = train_df['category'].astype(str)\r\n",
        "validation_df['category'] = validation_df['category'].astype(str)\r\n",
        "test_df['category'] = validation_df['category'].astype(str)\r\n",
        "\r\n",
        "total_train = train_df.shape[0]\r\n",
        "total_validate = validation_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os7-L9zb-bBX"
      },
      "source": [
        "import random\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "\r\n",
        "sample = random.choice(test_filenames)\r\n",
        "image = load_img(path_test_pokemon + sample)\r\n",
        "plt.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADOgPTywb2yY"
      },
      "source": [
        "Ensemble d'entraînement, test et validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sMG5ayDb7XO"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "image_size = 32\r\n",
        "\r\n",
        "\r\n",
        "#Images d'entrainement\r\n",
        "train_datagen=ImageDataGenerator(rescale=1./255)\r\n",
        "train_generator = train_datagen.flow_from_dataframe(\r\n",
        "    train_df, \r\n",
        "    path_train_pokemon,\r\n",
        "    x_col='filename',\r\n",
        "    y_col='category',\r\n",
        "    target_size=(image_size,image_size),\r\n",
        "    batch_size=batch_size\r\n",
        ")\r\n",
        "\r\n",
        "#Images de validation\r\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)\r\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\r\n",
        "    validation_df, \r\n",
        "    path_validation_pokemon, \r\n",
        "    x_col='filename',\r\n",
        "    y_col='category',\r\n",
        "    target_size=(image_size, image_size),\r\n",
        "    batch_size=batch_size\r\n",
        ")\r\n",
        "\r\n",
        "#Images de test\r\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\r\n",
        "test_generator = test_datagen.flow_from_dataframe(\r\n",
        "    test_df, \r\n",
        "    path_test_pokemon, \r\n",
        "    x_col='filename',\r\n",
        "    y_col='category',\r\n",
        "    target_size=(image_size, image_size),\r\n",
        "    batch_size=batch_size\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHsB9LWQOs6"
      },
      "source": [
        "Entraînement du réseau de neurone.\r\n",
        "\r\n",
        "On utilise un VGG pré-entraîné sur imagenet\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJoge4-A3lZj"
      },
      "source": [
        "Import VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRMQ9Je_3j8A"
      },
      "source": [
        "#VGG pré entraîné sur imagenet\r\n",
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\r\n",
        "model_vgg16_conv.summary()\r\n",
        "\r\n",
        "#Mon input c'est du 40 40 3\r\n",
        "input = Input(shape=(32, 32, 3),name = 'image_input')\r\n",
        "\r\n",
        "output_vgg16_conv = model_vgg16_conv(input)\r\n",
        "\r\n",
        "#On rajoute quelques layers\r\n",
        "x = Flatten(name='flatten')(output_vgg16_conv)\r\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\r\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\r\n",
        "x = Dense(151, activation='softmax', name='predictions')(x)\r\n",
        "\r\n",
        "#Mon modele à moi\r\n",
        "my_model = Model(inputs=input, outputs=x)\r\n",
        "\r\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21p8a0i66ARv"
      },
      "source": [
        "C'est parti pour l'entraînnement !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFm-A4AE5_6q"
      },
      "source": [
        "my_model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=3e-4),\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt9-GiXjObGa"
      },
      "source": [
        "print(\"Train_data shape\", np.shape(Train_data))\r\n",
        "print(\"Train labels shape\", np.shape(Train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2JOOta3IbDX"
      },
      "source": [
        "history = my_model.fit(train_generator,\r\n",
        "                    steps_per_epoch=total_train//batch_size,\r\n",
        "                    validation_data=validation_generator,\r\n",
        "                    validation_steps=total_validate//batch_size,\r\n",
        "                    epochs=30,\r\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}